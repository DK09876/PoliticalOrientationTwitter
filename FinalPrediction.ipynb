{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Models Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "581/581 [==============================] - 1s 419us/step - loss: 15.5341 - accuracy: 0.5033\n",
      "Epoch 2/50\n",
      "581/581 [==============================] - 0s 400us/step - loss: 0.8749 - accuracy: 0.5004\n",
      "Epoch 3/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.8678 - accuracy: 0.5003\n",
      "Epoch 4/50\n",
      "581/581 [==============================] - 0s 399us/step - loss: 0.8310 - accuracy: 0.5044\n",
      "Epoch 5/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.9279 - accuracy: 0.5070\n",
      "Epoch 6/50\n",
      "581/581 [==============================] - 0s 395us/step - loss: 0.7880 - accuracy: 0.5048\n",
      "Epoch 7/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.8624 - accuracy: 0.5060\n",
      "Epoch 8/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.8677 - accuracy: 0.5030\n",
      "Epoch 9/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.9081 - accuracy: 0.5030\n",
      "Epoch 10/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.8457 - accuracy: 0.5018\n",
      "Epoch 11/50\n",
      "581/581 [==============================] - 0s 399us/step - loss: 0.8484 - accuracy: 0.5050\n",
      "Epoch 12/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.8472 - accuracy: 0.5052\n",
      "Epoch 13/50\n",
      "581/581 [==============================] - 0s 400us/step - loss: 0.8315 - accuracy: 0.5066\n",
      "Epoch 14/50\n",
      "581/581 [==============================] - 0s 399us/step - loss: 0.8149 - accuracy: 0.5039\n",
      "Epoch 15/50\n",
      "581/581 [==============================] - 0s 407us/step - loss: 0.8072 - accuracy: 0.5030\n",
      "Epoch 16/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.8068 - accuracy: 0.5003\n",
      "Epoch 17/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.7985 - accuracy: 0.5059\n",
      "Epoch 18/50\n",
      "581/581 [==============================] - 0s 394us/step - loss: 0.8013 - accuracy: 0.5038\n",
      "Epoch 19/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.8813 - accuracy: 0.5072\n",
      "Epoch 20/50\n",
      "581/581 [==============================] - 0s 459us/step - loss: 0.7922 - accuracy: 0.5076\n",
      "Epoch 21/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.8073 - accuracy: 0.5044\n",
      "Epoch 22/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.8268 - accuracy: 0.5048\n",
      "Epoch 23/50\n",
      "581/581 [==============================] - 0s 395us/step - loss: 0.8157 - accuracy: 0.5082\n",
      "Epoch 24/50\n",
      "581/581 [==============================] - 0s 409us/step - loss: 0.8424 - accuracy: 0.5052\n",
      "Epoch 25/50\n",
      "581/581 [==============================] - 0s 395us/step - loss: 0.8430 - accuracy: 0.5068\n",
      "Epoch 26/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.8045 - accuracy: 0.5025\n",
      "Epoch 27/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.8235 - accuracy: 0.5080\n",
      "Epoch 28/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.8013 - accuracy: 0.5054\n",
      "Epoch 29/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.8562 - accuracy: 0.5024\n",
      "Epoch 30/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.8300 - accuracy: 0.5037\n",
      "Epoch 31/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.7960 - accuracy: 0.5050\n",
      "Epoch 32/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.7959 - accuracy: 0.5071\n",
      "Epoch 33/50\n",
      "581/581 [==============================] - 0s 400us/step - loss: 0.8175 - accuracy: 0.5018\n",
      "Epoch 34/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.7923 - accuracy: 0.5031\n",
      "Epoch 35/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.8424 - accuracy: 0.5033\n",
      "Epoch 36/50\n",
      "581/581 [==============================] - 0s 395us/step - loss: 0.8010 - accuracy: 0.5007\n",
      "Epoch 37/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.7742 - accuracy: 0.5045\n",
      "Epoch 38/50\n",
      "581/581 [==============================] - 0s 395us/step - loss: 0.8054 - accuracy: 0.5024\n",
      "Epoch 39/50\n",
      "581/581 [==============================] - 0s 399us/step - loss: 0.8037 - accuracy: 0.5042\n",
      "Epoch 40/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.7895 - accuracy: 0.5086\n",
      "Epoch 41/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.7989 - accuracy: 0.5039\n",
      "Epoch 42/50\n",
      "581/581 [==============================] - 0s 403us/step - loss: 0.7848 - accuracy: 0.5046\n",
      "Epoch 43/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.7862 - accuracy: 0.5081\n",
      "Epoch 44/50\n",
      "581/581 [==============================] - 0s 445us/step - loss: 0.7755 - accuracy: 0.5066\n",
      "Epoch 45/50\n",
      "581/581 [==============================] - 0s 399us/step - loss: 0.8622 - accuracy: 0.5050\n",
      "Epoch 46/50\n",
      "581/581 [==============================] - 0s 395us/step - loss: 0.7720 - accuracy: 0.5018\n",
      "Epoch 47/50\n",
      "581/581 [==============================] - 0s 397us/step - loss: 0.8210 - accuracy: 0.5049\n",
      "Epoch 48/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.7770 - accuracy: 0.5069\n",
      "Epoch 49/50\n",
      "581/581 [==============================] - 0s 396us/step - loss: 0.7852 - accuracy: 0.5043\n",
      "Epoch 50/50\n",
      "581/581 [==============================] - 0s 398us/step - loss: 0.7745 - accuracy: 0.5053\n"
     ]
    }
   ],
   "source": [
    "%run Classifier.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import functools \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/dk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stop words list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to extract words from a text\n",
    "def extract_words(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Remove non-alphabetic characters\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(username):\n",
    "    query = \"(from:\" +username + \") until:2023-02-18 since:2010-01-01\"\n",
    "    tweets = []\n",
    "    limit = 100\n",
    "\n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "        if len(tweets) == limit:\n",
    "            break\n",
    "        else:\n",
    "           #political or not code\n",
    "           tweets.append(extract_words(tweet.content))\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(\"Enter Twitter user\")\n",
    "tweets = get_tweets(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "userWords = []\n",
    "for index,tweet in enumerate(tweets):\n",
    "    for index2,word in enumerate(tweet):\n",
    "        if word in wordbank:\n",
    "            userWords.append(word)\n",
    "            \n",
    "\n",
    "userWordsDF = pd.DataFrame(userWords,columns = ['Tweets'])\n",
    "userWordsEncoded = le.transform(userWordsDF[\"Tweets\"])\n",
    "userWordsEncodedDF = pd.DataFrame(userWordsEncoded,columns=['Tweets'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by DecisionTreeClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DecisionTreePred \u001b[39m=\u001b[39m stTreeEntropy\u001b[39m.\u001b[39;49mpredict(userWordsEncodedDF)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/tree/_classes.py:426\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[1;32m    427\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    428\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/tree/_classes.py:392\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 392\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    394\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[1;32m    395\u001b[0m     ):\n\u001b[1;32m    396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by DecisionTreeClassifier."
     ]
    }
   ],
   "source": [
    "DecisionTreePred = stTreeEntropy.predict(userWordsEncodedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreePred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrat = 0\n",
    "Republican = 0\n",
    "\n",
    "for item in DecisionTreePred:\n",
    "    if item == 0:\n",
    "        Democrat +=1 \n",
    "    else:\n",
    "        Republican +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result is -0.9131403118040089\n"
     ]
    }
   ],
   "source": [
    "Result = (Democrat - Republican)/(Democrat + Republican)\n",
    "\n",
    "print (\"The final result is\",(Result)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveMethodPred = naiveMethod.predict(userWordsEncodedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveMethodPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrat = 0\n",
    "Republican = 0\n",
    "\n",
    "for item in naiveMethodPred:\n",
    "    if item == 0:\n",
    "        Democrat +=1 \n",
    "    else:\n",
    "        Republican +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result is 10.0\n"
     ]
    }
   ],
   "source": [
    "Result = (Democrat - Republican)/(Democrat + Republican)\n",
    "\n",
    "print (\"The final result is\",(Result)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnMethodPred = knnMethod.predict(userWordsEncodedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnMethodPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrat = 0\n",
    "Republican = 0\n",
    "\n",
    "for item in knnMethodPred:\n",
    "    if item == 0:\n",
    "        Democrat +=1 \n",
    "    else:\n",
    "        Republican +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result is 0.09651076466221231\n"
     ]
    }
   ],
   "source": [
    "Result = (Democrat - Republican)/(Democrat + Republican)\n",
    "\n",
    "print (\"The final result is\",(Result)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaMethodPred = abc2.predict(userWordsEncodedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaMethodPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Democrat = 0\n",
    "Republican = 0\n",
    "\n",
    "for item in adaMethodPred:\n",
    "    if item == 0:\n",
    "        Democrat +=1 \n",
    "    else:\n",
    "        Republican +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result is -1.2397921306607276\n"
     ]
    }
   ],
   "source": [
    "Result = (Democrat - Republican)/(Democrat + Republican)\n",
    "\n",
    "print (\"The final result is\",(Result)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 325us/step\n"
     ]
    }
   ],
   "source": [
    "annMethodPred = classifier.predict(userWordsEncodedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45634073],\n",
       "       [0.3914778 ],\n",
       "       [0.38154992],\n",
       "       ...,\n",
       "       [0.3561659 ],\n",
       "       [0.47705457],\n",
       "       [0.42222828]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annMethodPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result is 10.0\n"
     ]
    }
   ],
   "source": [
    "array_result = []\n",
    "for i in range(len(annMethodPred)):\n",
    "  if annMethodPred[i][0] >= 0.5:\n",
    "    array_result.append(1)\n",
    "  else:\n",
    "    array_result.append(0)\n",
    "Democrat_Neural = 0\n",
    "Republican_Neural = 0\n",
    "\n",
    "\n",
    "for item in array_result:\n",
    "    if item == 0:\n",
    "        Democrat_Neural +=1 \n",
    "    else:\n",
    "        Republican_Neural +=1\n",
    "Result_Neural = (Democrat_Neural - Republican_Neural)/(Democrat_Neural + Republican_Neural)\n",
    "print (\"The final result is\",(Result_Neural)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final result is 0\n"
     ]
    }
   ],
   "source": [
    "Result = (Democrat - Republican)/(Democrat + Republican)\n",
    "\n",
    "print (\"The final result is\",int(Result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
