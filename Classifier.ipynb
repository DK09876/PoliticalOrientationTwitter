{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>since</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mayor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>vi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lyles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>instrumental</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77422</th>\n",
       "      <td>77422</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77423</th>\n",
       "      <td>77423</td>\n",
       "      <td>tour</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77424</th>\n",
       "      <td>77424</td>\n",
       "      <td>incredible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77425</th>\n",
       "      <td>77425</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77426</th>\n",
       "      <td>77426</td>\n",
       "      <td>https</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        Tweets  Orientation\n",
       "0               0         since            0\n",
       "1               1         mayor            0\n",
       "2               2            vi            0\n",
       "3               3         lyles            0\n",
       "4               4  instrumental            0\n",
       "...           ...           ...          ...\n",
       "77422       77422         night            1\n",
       "77423       77423          tour            1\n",
       "77424       77424    incredible            1\n",
       "77425       77425         night            1\n",
       "77426       77426         https            1\n",
       "\n",
       "[77427 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF = pd.read_excel(\"TweetsDataBase.xlsx\")\n",
    "tweetsDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = tweetsDF[[\"Tweets\"]]\n",
    "Target =tweetsDF[[\"Orientation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "wordbank =  Features[\"Tweets\"].unique()\n",
    "le.fit(wordbank)\n",
    "encodedWords = le.transform(Features[\"Tweets\"])\n",
    "encodedDF = pd.DataFrame(encodedWords,columns=['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77422</th>\n",
       "      <td>6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77423</th>\n",
       "      <td>10088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77424</th>\n",
       "      <td>4919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77425</th>\n",
       "      <td>6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77426</th>\n",
       "      <td>4729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77427 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweets\n",
       "0        9152\n",
       "1        6048\n",
       "2       10652\n",
       "3        5870\n",
       "4        5051\n",
       "...       ...\n",
       "77422    6610\n",
       "77423   10088\n",
       "77424    4919\n",
       "77425    6610\n",
       "77426    4729\n",
       "\n",
       "[77427 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = encodedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Features_train, Features_test, Target_train, Target_test = train_test_split(Features, Target, random_state=0, train_size = .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stTreeEntropy = tree.DecisionTreeClassifier(criterion=\"entropy\")           # defining decision tree classifier (basic)\n",
    "stTreeEntropy = stTreeEntropy.fit(Features_train,Target_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors as nn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"n_neighbors\": range(1, 20)}\n",
    "gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "gridsearch.fit(Features_train,Target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnMethod = KNeighborsClassifier(n_neighbors=101)\n",
    "knnMethod = knnMethod.fit(Features_train,Target_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc2 = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier( max_depth=5, random_state=370, criterion='entropy'), \n",
    "    n_estimators=100, random_state=370 )\n",
    "\n",
    "abc2 = abc2.fit(Features_train,Target_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Nueral Network (Accuracy was too low so omit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from keras.datasets import mnist\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sc = StandardScaler()\n",
    "#Features_train_1 = sc.fit_transform(Features_train)\n",
    "#Features_test_1 = sc.transform(Features_test)\n",
    "#Target_train_1 = sc.fit_transform(Target_train)\n",
    "#Target_test_1 = sc.transform(Target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# from keras.datasets import cifar10\n",
    "# #classifier = Sequential()\n",
    "# # Add input layer and first hidden layer\n",
    "# #classifier.add( Dense(units=9, activation = 'relu', input_dim = 4) )  \n",
    "# # Add second hidden layer (previous layer is new input)\n",
    "# #classifier.add( Dense(units=9, activation = 'relu', input_dim = 4) )\n",
    "# # Add the output layer\n",
    "# #classifier.add( Dense(1, activation = 'sigmoid') ) \n",
    "# classifier = Sequential()\n",
    "# #Defining layers of the model\n",
    "# #classifier.add(Flatten(input_shape=(32,32,3)) # 32*32*3 = 3072\n",
    "# classifier.add( Dense(units=16, activation = 'relu', input_dim = 1) )  \n",
    "# classifier.add( Dense(units=16, activation = 'relu', input_dim = 1) )\n",
    "# classifier.add( Dense(1, activation = 'sigmoid') ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])  # <-- adam performs stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annF = classifier.fit(Features_train,Target_train, batch_size = 100, epochs = 50, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SVM (Training time too long so omit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(Features_train)\n",
    "# X_test = sc.transform(Features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# from sklearn.svm import SVC      # <-- Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the classifier\n",
    "# svmMethod = SVC(kernel='linear', probability=True) \n",
    "\n",
    "# # Fit using the classifier\n",
    "\n",
    "# svmMethod = svmMethod.fit(Features_train,Target_train) \n",
    "# #clfF = clf.fit(X_train,Target_train) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes (Not reliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import io\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import scipy.stats as ss\n",
    "# import seaborn as sns\n",
    "# import mpl_toolkits.mplot3d \n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython.display import HTML\n",
    "# from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Naive Baiyes\n",
    "# from sklearn.datasets import load_iris     # <--- the numbers are in cm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naiveMethod = GaussianNB()\n",
    "# naiveMethod = naiveMethod.fit(Features_train,Target_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
